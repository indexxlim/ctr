import pandas as pd
import numpy as np
from sklearn.metrics import roc_auc_score, log_loss
import time
import os

print("ğŸš€ CTR Baseline Model Training")
print("="*50)

# 1. ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ
start_time = time.time()
print("Loading preprocessed data...")

if os.path.exists("./data/processed/train_data.parquet"):
    train_data = pd.read_parquet("./data/processed/train_data.parquet")
    val_data = pd.read_parquet("./data/processed/val_data.parquet")
    print(f"Train: {len(train_data):,}, Val: {len(val_data):,}")
else:
    print("Preprocessed data not found. Please run: python train.py --prepare-data")
    exit(1)

# 2. í”¼ì²˜/ë¼ë²¨ ë¶„ë¦¬
X_train = train_data.drop(columns=["clicked"])
y_train = train_data["clicked"]
X_val = val_data.drop(columns=["clicked"])
y_val = val_data["clicked"]

print(f"Features: {len(X_train.columns)}, Train positive rate: {y_train.mean():.4f}")
load_time = time.time() - start_time
print(f"Data loaded in {load_time:.2f}s")

# 3. ë²”ì£¼í˜• feature ì‹ë³„ (ì„ë² ë”© í”¼ì²˜ëŠ” ì œì™¸)
# feat_*, l_feat_*ì€ ì„ë² ë”©ì´ë¯€ë¡œ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ì²˜ë¦¬
categorical_cols = [col for col in X_train.columns if col in ["gender", "age_group", "inventory_id", "day_of_week", "hour"]]
print(f"Categorical features: {len(categorical_cols)}")

# 4. LightGBM ëª¨ë¸ (ìµœì í™”ëœ ì„¤ì •)
from lightgbm import LGBMClassifier

print("\nğŸ¯ Training LightGBM baseline...")
train_start = time.time()

model = LGBMClassifier(
    n_estimators=500,     # ë” ë§ì€ íŠ¸ë¦¬
    learning_rate=0.05,   # ë” ë‚®ì€ í•™ìŠµë¥ 
    max_depth=8,          # ë” ê¹Šì€ íŠ¸ë¦¬
    subsample=0.8,
    colsample_bytree=0.8,
    reg_alpha=0.1,        # L1 ì •ê·œí™”
    reg_lambda=0.1,       # L2 ì •ê·œí™”
    metric="auc",
    objective="binary",
    random_state=42,
    verbose=-1,
    n_jobs=-1             # ë©€í‹°í”„ë¡œì„¸ì‹±
)

# 5. í•™ìŠµ (validation setìœ¼ë¡œ early stopping)
from lightgbm import log_evaluation, early_stopping

model.fit(
    X_train, y_train,
    eval_set=[(X_val, y_val)],
    categorical_feature=categorical_cols,
    eval_metric='auc',
    callbacks=[
        log_evaluation(period=10),  # 10 iterationë§ˆë‹¤ ì§„í–‰ìƒí™© ì¶œë ¥
        early_stopping(stopping_rounds=50)  # 50 roundsë™ì•ˆ ê°œì„  ì—†ìœ¼ë©´ ì¡°ê¸° ì¢…ë£Œ
    ]
)

train_time = time.time() - train_start
print(f"Training completed in {train_time:.2f}s")

# 6. ì˜ˆì¸¡ ë° í‰ê°€
print("\nğŸ“Š Evaluation Results:")

# Validation í‰ê°€
val_preds = model.predict_proba(X_val)[:, 1]
val_auc = roc_auc_score(y_val, val_preds)
val_logloss = log_loss(y_val, val_preds)

print(f"Validation AUC: {val_auc:.4f}")
print(f"Validation LogLoss: {val_logloss:.4f}")

# Feature importance ì¶œë ¥
print(f"\nğŸ” Top 10 Important Features:")
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print(feature_importance.head(10).to_string(index=False))

# 7. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥
import pickle
from datetime import datetime

timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
save_dir = f"./experiments/baseline_{timestamp}"
os.makedirs(save_dir, exist_ok=True)

print(f"\nğŸ’¾ Saving baseline results to: {save_dir}")

# ëª¨ë¸ ì €ì¥
with open(f"{save_dir}/lightgbm_model.pkl", 'wb') as f:
    pickle.dump(model, f)

# Feature importance ì €ì¥
feature_importance.to_csv(f"{save_dir}/feature_importance.csv", index=False)

# ê²°ê³¼ ì €ì¥
results = {
    'timestamp': timestamp,
    'model_type': 'LightGBM',
    'validation_auc': val_auc,
    'validation_logloss': val_logloss,
    'training_time_seconds': train_time,
    'n_estimators': 500,
    'learning_rate': 0.05,
    'max_depth': 8,
    'num_features': len(X_train.columns),
    'train_samples': len(X_train),
    'val_samples': len(X_val)
}

import json
with open(f"{save_dir}/results.json", 'w') as f:
    json.dump(results, f, indent=2)

# ì˜ˆì¸¡ê°’ ì €ì¥ (ì¶”í›„ ì•™ìƒë¸”ì´ë‚˜ ë¶„ì„ìš©)
val_predictions = pd.DataFrame({
    'val_predictions': val_preds,
    'val_labels': y_val
})
val_predictions.to_csv(f"{save_dir}/val_predictions.csv", index=False)

print(f"âœ… Baseline model and results saved successfully!")
print(f"ğŸ“ Files saved:")
print(f"   - lightgbm_model.pkl (model)")
print(f"   - feature_importance.csv")
print(f"   - results.json")
print(f"   - val_predictions.csv")
